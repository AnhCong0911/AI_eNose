// Generated by TFLite Support.
package org.tensorflow.lite.support.gasclassification;

import android.content.Context;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.FloatBuffer;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import org.tensorflow.lite.DataType;
import org.tensorflow.lite.Tensor;
import org.tensorflow.lite.Tensor.QuantizationParams;
import org.tensorflow.lite.support.common.FileUtil;
import org.tensorflow.lite.support.common.TensorProcessor;
import org.tensorflow.lite.support.common.ops.CastOp;
import org.tensorflow.lite.support.common.ops.DequantizeOp;
import org.tensorflow.lite.support.common.ops.NormalizeOp;
import org.tensorflow.lite.support.common.ops.QuantizeOp;
import org.tensorflow.lite.support.label.Category;
import org.tensorflow.lite.support.label.TensorLabel;
import org.tensorflow.lite.support.metadata.MetadataExtractor;
import org.tensorflow.lite.support.metadata.schema.NormalizationOptions;
import org.tensorflow.lite.support.model.Model;
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer;

/** Wrapper class of model GasNetV5.1 gas detector (Version: v5.1) */
public class GasDetectorModel {
  private final Metadata metadata;
  private final Model model;
  private static final String MODEL_NAME = "gasnet.tflite";
  private TensorProcessor inputtensorPreprocessor;
  private TensorProcessor outputtensorsPostprocessor;

  /** Output wrapper of {@link GasDetectorModel} */
  public static class Outputs {
    private final TensorBuffer outputtensors;
    private final List<String> outputtensorsLabels;
    private final TensorProcessor outputtensorsPostprocessor;

    public List<Category> getOutputtensorsAsCategoryList() {
      return new TensorLabel(outputtensorsLabels, postprocessOutputtensors(outputtensors)).getCategoryList();
    }

    Outputs(Metadata metadata, TensorProcessor outputtensorsPostprocessor) {
      outputtensors = TensorBuffer.createFixedSize(metadata.getOutputtensorsShape(), metadata.getOutputtensorsType());
      outputtensorsLabels = metadata.getOutputtensorsLabels();
      this.outputtensorsPostprocessor = outputtensorsPostprocessor;
    }

    Map<Integer, Object> getBuffer() {
      Map<Integer, Object> outputs = new HashMap<>();
      outputs.put(0, outputtensors.getBuffer());
      return outputs;
    }

    private TensorBuffer postprocessOutputtensors(TensorBuffer tensorBuffer) {
      return outputtensorsPostprocessor.process(tensorBuffer);
    }
  }

  /** Metadata accessors of {@link GasDetectorModel} */
  public static class Metadata {
    private final int[] inputtensorShape;
    private final DataType inputtensorDataType;
    private final QuantizationParams inputtensorQuantizationParams;
    private final float[] inputtensorMean;
    private final float[] inputtensorStddev;
    private final int[] outputtensorsShape;
    private final DataType outputtensorsDataType;
    private final QuantizationParams outputtensorsQuantizationParams;
    private final List<String> outputtensorsLabels;

    public Metadata(ByteBuffer buffer, Model model) throws IOException {
      MetadataExtractor extractor = new MetadataExtractor(buffer);
      Tensor inputtensorTensor = model.getInputTensor(0);
      inputtensorShape = inputtensorTensor.shape();
      inputtensorDataType = inputtensorTensor.dataType();
      inputtensorQuantizationParams = inputtensorTensor.quantizationParams();
      NormalizationOptions inputtensorNormalizationOptions =
          (NormalizationOptions) extractor.getInputTensorMetadata(0).processUnits(0).options(new NormalizationOptions());
      FloatBuffer inputtensorMeanBuffer = inputtensorNormalizationOptions.meanAsByteBuffer().asFloatBuffer();
      inputtensorMean = new float[inputtensorMeanBuffer.limit()];
      inputtensorMeanBuffer.get(inputtensorMean);
      FloatBuffer inputtensorStddevBuffer = inputtensorNormalizationOptions.stdAsByteBuffer().asFloatBuffer();
      inputtensorStddev = new float[inputtensorStddevBuffer.limit()];
      inputtensorStddevBuffer.get(inputtensorStddev);
      Tensor outputtensorsTensor = model.getOutputTensor(0);
      outputtensorsShape = outputtensorsTensor.shape();
      outputtensorsDataType = outputtensorsTensor.dataType();
      outputtensorsQuantizationParams = outputtensorsTensor.quantizationParams();
      String outputtensorsLabelsFileName =
          extractor.getOutputTensorMetadata(0).associatedFiles(0).name();
      outputtensorsLabels = FileUtil.loadLabels(extractor.getAssociatedFile(outputtensorsLabelsFileName));
    }

    public int[] getInputtensorShape() {
      return Arrays.copyOf(inputtensorShape, inputtensorShape.length);
    }

    public DataType getInputtensorType() {
      return inputtensorDataType;
    }

    public QuantizationParams getInputtensorQuantizationParams() {
      return inputtensorQuantizationParams;
    }

    public float[] getInputtensorMean() {
      return Arrays.copyOf(inputtensorMean, inputtensorMean.length);
    }

    public float[] getInputtensorStddev() {
      return Arrays.copyOf(inputtensorStddev, inputtensorStddev.length);
    }

    public int[] getOutputtensorsShape() {
      return Arrays.copyOf(outputtensorsShape, outputtensorsShape.length);
    }

    public DataType getOutputtensorsType() {
      return outputtensorsDataType;
    }

    public QuantizationParams getOutputtensorsQuantizationParams() {
      return outputtensorsQuantizationParams;
    }

    public List<String> getOutputtensorsLabels() {
      return outputtensorsLabels;
    }
  }

  public Metadata getMetadata() {
    return metadata;
  }

  /**
   * Creates interpreter and loads associated files if needed.
   *
   * @throws IOException if an I/O error occurs when loading the tflite model.
   */
  public static GasDetectorModel newInstance(Context context) throws IOException {
    return newInstance(context, MODEL_NAME, new Model.Options.Builder().build());
  }

  /**
   * Creates interpreter and loads associated files if needed, but loading another model in the same
   * input / output structure with the original one.
   *
   * @throws IOException if an I/O error occurs when loading the tflite model.
   */
  public static GasDetectorModel newInstance(Context context, String modelPath) throws IOException {
    return newInstance(context, modelPath, new Model.Options.Builder().build());
  }

  /**
   * Creates interpreter and loads associated files if needed, with running options configured.
   *
   * @throws IOException if an I/O error occurs when loading the tflite model.
   */
  public static GasDetectorModel newInstance(Context context, Model.Options runningOptions) throws IOException {
    return newInstance(context, MODEL_NAME, runningOptions);
  }

  /**
   * Creates interpreter for a user-specified model.
   *
   * @throws IOException if an I/O error occurs when loading the tflite model.
   */
  public static GasDetectorModel newInstance(Context context, String modelPath, Model.Options runningOptions) throws IOException {
    Model model = Model.createModel(context, modelPath, runningOptions);
    Metadata metadata = new Metadata(model.getData(), model);
    GasDetectorModel instance = new GasDetectorModel(model, metadata);
    instance.resetInputtensorPreprocessor(
        instance.buildDefaultInputtensorPreprocessor());
    instance.resetOutputtensorsPostprocessor(
        instance.buildDefaultOutputtensorsPostprocessor());
    return instance;
  }


  public void resetInputtensorPreprocessor(TensorProcessor processor) {
    inputtensorPreprocessor = processor;
  }

  public void resetOutputtensorsPostprocessor(TensorProcessor processor) {
    outputtensorsPostprocessor = processor;
  }

  /** Triggers the model. */
  public Outputs process(TensorBuffer inputtensor) {
    Outputs outputs = new Outputs(metadata, outputtensorsPostprocessor);
    Object[] inputBuffers = preprocessInputs(inputtensor);
    model.run(inputBuffers, outputs.getBuffer());
    return outputs;
  }

  /** Closes the model. */
  public void close() {
    model.close();
  }

  private GasDetectorModel(Model model, Metadata metadata) {
    this.model = model;
    this.metadata = metadata;
  }

  private TensorProcessor buildDefaultInputtensorPreprocessor() {
    TensorProcessor.Builder builder = new TensorProcessor.Builder()
        .add(new NormalizeOp(metadata.getInputtensorMean(), metadata.getInputtensorStddev()))
        .add(new QuantizeOp(
            metadata.getInputtensorQuantizationParams().getZeroPoint(),
            metadata.getInputtensorQuantizationParams().getScale()))
        .add(new CastOp(metadata.getInputtensorType()));
    return builder.build();
  }

  private TensorProcessor buildDefaultOutputtensorsPostprocessor() {
    TensorProcessor.Builder builder = new TensorProcessor.Builder()
        .add(new DequantizeOp(
            metadata.getOutputtensorsQuantizationParams().getZeroPoint(),
            metadata.getOutputtensorsQuantizationParams().getScale()));
    return builder.build();
  }

  private Object[] preprocessInputs(TensorBuffer inputtensor) {
    inputtensor = inputtensorPreprocessor.process(inputtensor);
    return new Object[] {inputtensor.getBuffer()};
  }
}

